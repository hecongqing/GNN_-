import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from tqdm import tqdm
import json
from datetime import datetime
from typing import Tuple

from .dataset import AliRecommendDataset
from .model import LightGCN
from .utils import (
    setup_logger, 
    set_random_seed, 
    load_config, 
    EarlyStopping,
    compute_metrics
)


class BPRLoss(nn.Module):
    """è´å¶æ–¯ä¸ªæ€§åŒ–æ’åºæŸå¤±å‡½æ•°"""
    
    def __init__(self):
        super().__init__()
        
    def forward(self, pos_scores: torch.Tensor, neg_scores: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—BPRæŸå¤±
        
        Args:
            pos_scores: æ­£æ ·æœ¬åˆ†æ•° [batch_size]
            neg_scores: è´Ÿæ ·æœ¬åˆ†æ•° [batch_size]
            
        Returns:
            BPRæŸå¤±
        """
        diff = pos_scores - neg_scores
        loss = -torch.log(torch.sigmoid(diff)).mean()
        return loss


class LightGCNTrainer:
    """LightGCNè®­ç»ƒå™¨"""
    
    def __init__(self, model: LightGCN, device: torch.device = None):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: LightGCNæ¨¡å‹
            device: è®¡ç®—è®¾å¤‡
        """
        self.model = model
        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        
        # æŸå¤±å‡½æ•°
        self.bpr_loss = BPRLoss()
        
    def create_bpr_batch(self, interaction_matrix: np.ndarray, 
                        batch_size: int = 1024) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        åˆ›å»ºBPRè®­ç»ƒæ‰¹æ¬¡
        
        Args:
            interaction_matrix: äº¤äº’çŸ©é˜µ
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            user_indices: ç”¨æˆ·ç´¢å¼•
            pos_item_indices: æ­£æ ·æœ¬ç‰©å“ç´¢å¼•
            neg_item_indices: è´Ÿæ ·æœ¬ç‰©å“ç´¢å¼•
        """
        # è·å–æ‰€æœ‰æ­£æ ·æœ¬
        users, pos_items = np.where(interaction_matrix > 0)
        n_positive = len(users)
        
        # éšæœºé‡‡æ ·æ‰¹æ¬¡
        batch_indices = np.random.choice(n_positive, min(batch_size, n_positive), replace=False)
        batch_users = users[batch_indices]
        batch_pos_items = pos_items[batch_indices]
        
        # ä¸ºæ¯ä¸ªæ­£æ ·æœ¬ç”Ÿæˆè´Ÿæ ·æœ¬
        batch_neg_items = []
        for user_idx in batch_users:
            neg_item = np.random.randint(0, self.model.n_items)
            while interaction_matrix[user_idx, neg_item] > 0:
                neg_item = np.random.randint(0, self.model.n_items)
            batch_neg_items.append(neg_item)
        
        return (
            torch.tensor(batch_users, dtype=torch.long, device=self.device),
            torch.tensor(batch_pos_items, dtype=torch.long, device=self.device),
            torch.tensor(batch_neg_items, dtype=torch.long, device=self.device)
        )
    
    def train_epoch(self, edge_index: torch.Tensor, interaction_matrix: np.ndarray,
                   optimizer: torch.optim.Optimizer, batch_size: int = 1024,
                   n_batches: int = 50) -> float:
        """
        è®­ç»ƒä¸€ä¸ªepoch
        
        Args:
            edge_index: è¾¹ç´¢å¼•
            interaction_matrix: äº¤äº’çŸ©é˜µ
            optimizer: ä¼˜åŒ–å™¨
            batch_size: æ‰¹æ¬¡å¤§å°
            n_batches: æ‰¹æ¬¡æ•°é‡
            
        Returns:
            å¹³å‡æŸå¤±
        """
        self.model.train()
        total_loss = 0.0
        
        for _ in range(n_batches):
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­è·å–åµŒå…¥
            user_embeddings, item_embeddings = self.model(edge_index)
            
            # åˆ›å»ºè®­ç»ƒæ‰¹æ¬¡
            user_indices, pos_item_indices, neg_item_indices = self.create_bpr_batch(
                interaction_matrix, batch_size
            )
            
            # è®¡ç®—é¢„æµ‹åˆ†æ•°
            pos_scores = self.model.predict(user_indices, pos_item_indices, 
                                          user_embeddings, item_embeddings)
            neg_scores = self.model.predict(user_indices, neg_item_indices,
                                          user_embeddings, item_embeddings)
            
            # è®¡ç®—æŸå¤±
            loss = self.bpr_loss(pos_scores, neg_scores)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / n_batches
    
    def train(self, edge_index: torch.Tensor, interaction_matrix: np.ndarray,
              n_epochs: int = 100, lr: float = 0.001, weight_decay: float = 1e-4,
              batch_size: int = 1024, n_batches: int = 50, 
              verbose: bool = True, eval_every: int = 10) -> dict:
        """
        å®Œæ•´è®­ç»ƒè¿‡ç¨‹
        
        Args:
            edge_index: è¾¹ç´¢å¼•
            interaction_matrix: äº¤äº’çŸ©é˜µ
            n_epochs: è®­ç»ƒè½®æ•°
            lr: å­¦ä¹ ç‡
            weight_decay: æƒé‡è¡°å‡
            batch_size: æ‰¹æ¬¡å¤§å°
            n_batches: æ¯ä¸ªepochçš„æ‰¹æ¬¡æ•°é‡
            verbose: æ˜¯å¦æ‰“å°è®­ç»ƒä¿¡æ¯
            eval_every: æ¯éš”å¤šå°‘è½®è¯„ä¼°ä¸€æ¬¡
            
        Returns:
            è®­ç»ƒå†å²ä¿¡æ¯
        """
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)
        
        # è®­ç»ƒå†å²
        history = {
            'loss': [],
            'epoch': []
        }
        
        # å°†è¾¹ç´¢å¼•ç§»åˆ°è®¾å¤‡ä¸Š
        edge_index = edge_index.to(self.device)
        
        if verbose:
            print(f"å¼€å§‹è®­ç»ƒLightGCNæ¨¡å‹...")
            print(f"è®¾å¤‡: {self.device}")
            print(f"ç”¨æˆ·æ•°: {self.model.n_users}, ç‰©å“æ•°: {self.model.n_items}")
            print(f"åµŒå…¥ç»´åº¦: {self.model.embedding_dim}, GCNå±‚æ•°: {self.model.n_layers}")
            print("-" * 50)
        
        for epoch in range(n_epochs):
            # è®­ç»ƒä¸€ä¸ªepoch
            avg_loss = self.train_epoch(
                edge_index, interaction_matrix, optimizer, 
                batch_size, n_batches
            )
            
            # è®°å½•è®­ç»ƒå†å²
            history['loss'].append(avg_loss)
            history['epoch'].append(epoch)
            
            # æ‰“å°è®­ç»ƒä¿¡æ¯
            if verbose and (epoch + 1) % eval_every == 0:
                print(f"Epoch {epoch + 1:3d}/{n_epochs} | Loss: {avg_loss:.4f}")
        
        if verbose:
            print("-" * 50)
            print("è®­ç»ƒå®Œæˆ!")
        
        return history
    
    def evaluate(self, edge_index: torch.Tensor, test_data: np.ndarray,
                 k: int = 20) -> dict:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        
        Args:
            edge_index: è¾¹ç´¢å¼•
            test_data: æµ‹è¯•æ•°æ® (user_id, item_id) pairs
            k: top-kæ¨è
            
        Returns:
            è¯„ä¼°æŒ‡æ ‡
        """
        self.model.eval()
        
        with torch.no_grad():
            # è·å–ç”¨æˆ·å’Œç‰©å“åµŒå…¥
            user_embeddings, item_embeddings = self.model(edge_index.to(self.device))
            
            # è®¡ç®—æ¨èæŒ‡æ ‡
            hit_count = 0
            total_users = len(set(test_data[:, 0]))
            
            for user_id in set(test_data[:, 0]):
                # è·å–è¯¥ç”¨æˆ·çš„æµ‹è¯•ç‰©å“
                user_test_items = set(test_data[test_data[:, 0] == user_id, 1])
                
                # ç”Ÿæˆæ¨è
                recommendations = self.model.recommend(
                    user_id, user_embeddings, item_embeddings, k
                ).cpu().numpy()
                
                # è®¡ç®—å‘½ä¸­ç‡
                if len(set(recommendations) & user_test_items) > 0:
                    hit_count += 1
            
            hit_rate = hit_count / total_users
        
        return {'hit_rate@{}'.format(k): hit_rate}


class LightGCNTrainingPipeline:
    """LightGCNè®­ç»ƒç®¡é“"""
    
    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–è®­ç»ƒç®¡é“
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½é…ç½®
        self.config = load_config(config_path) if config_path else load_config('')
        
        # è®¾ç½®éšæœºç§å­
        set_random_seed(42)
        
        # è®¾ç½®è®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # è®¾ç½®æ—¥å¿—
        log_dir = 'outputs/logs'
        os.makedirs(log_dir, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_file = os.path.join(log_dir, f'training_{timestamp}.log')
        self.logger = setup_logger('Training', log_file)
        
        self.logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        self.logger.info(f"é…ç½®: {json.dumps(self.config, indent=2, ensure_ascii=False)}")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.dataset = None
        self.model = None
        self.trainer = None
        self.optimizer = None
        self.early_stopping = None
        
    def prepare_data(self):
        """å‡†å¤‡æ•°æ®"""
        self.logger.info("å¼€å§‹å‡†å¤‡æ•°æ®...")
        
        # åˆå§‹åŒ–æ•°æ®é›†
        self.dataset = AliRecommendDataset()
        
        # å°è¯•åŠ è½½é¢„å¤„ç†æ•°æ®
        if not self.dataset.load_processed_data():
            self.logger.info("æœªæ‰¾åˆ°é¢„å¤„ç†æ•°æ®ï¼Œå¼€å§‹æ•°æ®é¢„å¤„ç†...")
            
            # åŠ è½½åŸå§‹æ•°æ®
            user_data, item_data = self.dataset.load_data()
            
            # é¢„å¤„ç†æ•°æ®
            interaction_matrix, edge_index = self.dataset.preprocess_data(behavior_types=[4])
            
            # ä¿å­˜é¢„å¤„ç†æ•°æ®
            self.dataset.save_processed_data()
        else:
            self.logger.info("æˆåŠŸåŠ è½½é¢„å¤„ç†æ•°æ®")
        
        # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        self.train_matrix, self.test_matrix = self.dataset.split_data(
            test_ratio=self.config['evaluation']['test_ratio']
        )
        
        # å°†è¾¹ç´¢å¼•ç§»åˆ°è®¾å¤‡
        self.edge_index = self.dataset.edge_index.to(self.device)
        
        self.logger.info(f"æ•°æ®å‡†å¤‡å®Œæˆ")
        self.logger.info(f"ç”¨æˆ·æ•°: {self.dataset.n_users}, ç‰©å“æ•°: {self.dataset.n_items}")
        self.logger.info(f"è®­ç»ƒäº¤äº’æ•°: {self.train_matrix.sum()}, æµ‹è¯•äº¤äº’æ•°: {self.test_matrix.sum()}")
        
    def build_model(self):
        """æ„å»ºæ¨¡å‹"""
        self.logger.info("å¼€å§‹æ„å»ºæ¨¡å‹...")
        
        model_config = self.config['model']
        
        # åˆ›å»ºæ¨¡å‹
        self.model = LightGCN(
            n_users=self.dataset.n_users,
            n_items=self.dataset.n_items,
            embedding_dim=model_config['embedding_dim'],
            n_layers=model_config['n_layers'],
            dropout=model_config['dropout']
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        self.trainer = LightGCNTrainer(self.model, self.device)
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        training_config = self.config['training']
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=training_config['learning_rate'],
            weight_decay=training_config['weight_decay']
        )
        
        # åˆ›å»ºæ—©åœæœºåˆ¶
        self.early_stopping = EarlyStopping(patience=10, min_delta=0.001)
        
        # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        self.logger.info(f"æ¨¡å‹æ„å»ºå®Œæˆ")
        self.logger.info(f"æ€»å‚æ•°æ•°: {total_params:,}")
        self.logger.info(f"å¯è®­ç»ƒå‚æ•°æ•°: {trainable_params:,}")
        
    def evaluate_model(self, interaction_matrix: np.ndarray) -> dict:
        """
        è¯„ä¼°æ¨¡å‹
        
        Args:
            interaction_matrix: æµ‹è¯•äº¤äº’çŸ©é˜µ
            
        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        self.model.eval()
        
        with torch.no_grad():
            # è·å–ç”¨æˆ·å’Œç‰©å“åµŒå…¥
            user_embeddings, item_embeddings = self.model(self.edge_index)
            
            # è·å–æ‰€æœ‰è¯„åˆ†é¢„æµ‹
            all_ratings = self.model.get_all_ratings(user_embeddings, item_embeddings)
            all_ratings = all_ratings.cpu().numpy()
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            metrics = compute_metrics(
                all_ratings, 
                interaction_matrix, 
                k=self.config['evaluation']['k']
            )
        
        return metrics
    
    def train(self, config=None):
        """è®­ç»ƒæ¨¡å‹"""
        if config:
            self.config.update(config)
            
        if self.dataset is None:
            self.prepare_data()
        
        if self.model is None:
            self.build_model()
        
        self.logger.info("å¼€å§‹è®­ç»ƒ...")
        
        training_config = self.config['training']
        best_f1 = 0.0
        best_epoch = 0
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(training_config['epochs']):
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss = self.trainer.train_epoch(
                edge_index=self.edge_index,
                interaction_matrix=self.train_matrix,
                optimizer=self.optimizer,
                batch_size=training_config['batch_size'],
                n_batches=100
            )
            
            # æ¯10ä¸ªepochè¯„ä¼°ä¸€æ¬¡
            if (epoch + 1) % 10 == 0:
                # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
                test_metrics = self.evaluate_model(self.test_matrix)
                
                self.logger.info(
                    f"Epoch {epoch+1}/{training_config['epochs']} - "
                    f"Train Loss: {train_loss:.4f}, "
                    f"Test F1: {test_metrics['f1']:.4f}"
                )
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if test_metrics['f1'] > best_f1:
                    best_f1 = test_metrics['f1']
                    best_epoch = epoch + 1
                    self.save_model('best_model.pt')
                    self.logger.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹ (F1: {best_f1:.4f})")
                
                # æ—©åœæ£€æŸ¥
                self.early_stopping(test_metrics['f1'])
                if self.early_stopping.early_stop:
                    self.logger.info(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
                    break
            else:
                if (epoch + 1) % 5 == 0:
                    self.logger.info(f"Epoch {epoch+1}/{training_config['epochs']} - Train Loss: {train_loss:.4f}")
        
        self.logger.info(f"è®­ç»ƒå®Œæˆï¼æœ€ä½³F1åˆ†æ•°: {best_f1:.4f} (ç¬¬ {best_epoch} è½®)")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆè¯„ä¼°
        self.load_model('best_model.pt')
        final_metrics = self.evaluate_model(self.test_matrix)
        
        self.logger.info("æœ€ç»ˆæµ‹è¯•ç»“æœ:")
        self.logger.info(f"Precision: {final_metrics['precision']:.4f}")
        self.logger.info(f"Recall: {final_metrics['recall']:.4f}")
        self.logger.info(f"F1-Score: {final_metrics['f1']:.4f}")
        
        return final_metrics
    
    def save_model(self, filename: str):
        """ä¿å­˜æ¨¡å‹"""
        model_dir = 'outputs/models'
        os.makedirs(model_dir, exist_ok=True)
        
        model_path = os.path.join(model_dir, filename)
        
        # ä¿å­˜æ¨¡å‹çŠ¶æ€å’Œç›¸å…³ä¿¡æ¯
        checkpoint = {
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'config': self.config,
            'n_users': self.dataset.n_users,
            'n_items': self.dataset.n_items,
            'user_mapping': self.dataset.user_mapping,
            'item_mapping': self.dataset.item_mapping
        }
        
        torch.save(checkpoint, model_path)
        self.logger.info(f"æ¨¡å‹å·²ä¿å­˜è‡³: {model_path}")
    
    def load_model(self, filename: str):
        """åŠ è½½æ¨¡å‹"""
        model_dir = 'outputs/models'
        model_path = os.path.join(model_dir, filename)
        
        if os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location=self.device)
            
            # å¦‚æœæ¨¡å‹æœªåˆå§‹åŒ–ï¼Œå…ˆåˆå§‹åŒ–
            if self.model is None:
                model_config = checkpoint['config']['model']
                self.model = LightGCN(
                    n_users=checkpoint['n_users'],
                    n_items=checkpoint['n_items'],
                    embedding_dim=model_config['embedding_dim'],
                    n_layers=model_config['n_layers'],
                    dropout=model_config['dropout']
                )
                self.model.to(self.device)
            
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.logger.info(f"æ¨¡å‹å·²ä» {model_path} åŠ è½½")
            return True
        else:
            self.logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
    
    def generate_recommendations(self, user_ids: list = None, k: int = 20):
        """
        ç”Ÿæˆæ¨èç»“æœ
        
        Args:
            user_ids: ç”¨æˆ·IDåˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä¸ºæ‰€æœ‰ç”¨æˆ·ç”Ÿæˆæ¨è
            k: æ¨èæ•°é‡
            
        Returns:
            æ¨èç»“æœåˆ—è¡¨ [(original_user_id, original_item_id), ...]
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè®­ç»ƒæˆ–åŠ è½½æ¨¡å‹")
        
        self.model.eval()
        recommendations = []
        
        # åˆ›å»ºåå‘æ˜ å°„
        reverse_user_mapping = {v: k for k, v in self.dataset.user_mapping.items()}
        reverse_item_mapping = {v: k for k, v in self.dataset.item_mapping.items()}
        
        with torch.no_grad():
            # è·å–ç”¨æˆ·å’Œç‰©å“åµŒå…¥
            user_embeddings, item_embeddings = self.model(self.edge_index)
            
            # å¦‚æœæœªæŒ‡å®šç”¨æˆ·ï¼Œä¸ºæ‰€æœ‰ç”¨æˆ·ç”Ÿæˆæ¨è
            if user_ids is None:
                user_indices = list(range(self.dataset.n_users))
            else:
                user_indices = [self.dataset.user_mapping[uid] for uid in user_ids 
                              if uid in self.dataset.user_mapping]
            
            for user_idx in user_indices:
                # ä¸ºç”¨æˆ·ç”Ÿæˆæ¨è
                recommended_items = self.model.recommend(user_idx, user_embeddings, item_embeddings, k)
                
                # è½¬æ¢å›åŸå§‹ID
                original_user_id = reverse_user_mapping[user_idx]
                
                for item_idx in recommended_items.cpu().numpy():
                    original_item_id = reverse_item_mapping[item_idx]
                    recommendations.append((original_user_id, original_item_id))
        
        return recommendations


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='LightGCNæ¨¡å‹è®­ç»ƒ')
    parser.add_argument('--config', type=str, default='config.json',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--epochs', type=int, default=None,
                       help='è®­ç»ƒè½®æ•°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--batch-size', type=int, default=None,
                       help='æ‰¹æ¬¡å¤§å°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--learning-rate', type=float, default=None,
                       help='å­¦ä¹ ç‡ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--embedding-dim', type=int, default=None,
                       help='åµŒå…¥ç»´åº¦ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹LightGCNæ¨¡å‹è®­ç»ƒ...")
    
    # åˆ›å»ºè®­ç»ƒç®¡é“
    pipeline = LightGCNTrainingPipeline(args.config)
    
    # è¦†ç›–é…ç½®å‚æ•°
    config_override = {}
    if args.epochs is not None:
        config_override.setdefault('training', {})['epochs'] = args.epochs
    if args.batch_size is not None:
        config_override.setdefault('training', {})['batch_size'] = args.batch_size
    if args.learning_rate is not None:
        config_override.setdefault('training', {})['learning_rate'] = args.learning_rate
    if args.embedding_dim is not None:
        config_override.setdefault('model', {})['embedding_dim'] = args.embedding_dim
    
    try:
        # è®­ç»ƒæ¨¡å‹
        print(f"ğŸ“Š ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
        if config_override:
            print(f"ğŸ”§ å‚æ•°è¦†ç›–: {config_override}")
            
        final_metrics = pipeline.train(config_override)
        
        print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“ˆ æœ€ç»ˆæŒ‡æ ‡:")
        print(f"  - Precision: {final_metrics['precision']:.4f}")
        print(f"  - Recall: {final_metrics['recall']:.4f}")
        print(f"  - F1-Score: {final_metrics['f1']:.4f}")
        
        # ç”Ÿæˆæ¨èç»“æœç¤ºä¾‹
        print("\nğŸ¯ ç”Ÿæˆæ¨èç»“æœç¤ºä¾‹...")
        sample_recommendations = pipeline.generate_recommendations(k=5)
        
        print(f"ä¸ºå‰3ä¸ªç”¨æˆ·ç”Ÿæˆçš„æ¨èç»“æœ:")
        current_user = None
        count = 0
        for user_id, item_id in sample_recommendations[:15]:
            if user_id != current_user:
                if count >= 3:
                    break
                current_user = user_id
                count += 1
                print(f"\nğŸ‘¤ ç”¨æˆ· {user_id} çš„æ¨è:")
            print(f"  - ç‰©å“ {item_id}")
        
        print("\nâœ… è®­ç»ƒå’Œæ¨èç”Ÿæˆå®Œæˆï¼")
        print("ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°: outputs/models/best_model.pt")
        print("ğŸ”„ è½¬æ¢ONNX: python service/convert_to_onnx.py --model-path outputs/models/best_model.pt")
        print("ğŸš€ å¯åŠ¨æœåŠ¡: python service/onnx_server.py --model-path outputs/models/best_model.onnx")
        print("ğŸ¨ å¯åŠ¨ç•Œé¢: python run_app.py")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise
    
    return 0


if __name__ == "__main__":
    main()