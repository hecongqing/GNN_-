import os
import torch
import torch.optim as optim
import numpy as np
from tqdm import tqdm
import json
from datetime import datetime

from .dataset import AliRecommendDataset
from .model import LightGCN, LightGCNTrainer
from .utils import (
    setup_logger, 
    set_random_seed, 
    load_config, 
    EarlyStopping,
    compute_metrics
)


class LightGCNTrainingPipeline:
    """LightGCNè®­ç»ƒç®¡é“"""
    
    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–è®­ç»ƒç®¡é“
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½é…ç½®
        self.config = load_config(config_path) if config_path else load_config('')
        
        # è®¾ç½®éšæœºç§å­
        set_random_seed(42)
        
        # è®¾ç½®è®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # è®¾ç½®æ—¥å¿—
        log_dir = 'outputs/logs'
        os.makedirs(log_dir, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_file = os.path.join(log_dir, f'training_{timestamp}.log')
        self.logger = setup_logger('Training', log_file)
        
        self.logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        self.logger.info(f"é…ç½®: {json.dumps(self.config, indent=2, ensure_ascii=False)}")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.dataset = None
        self.model = None
        self.trainer = None
        self.optimizer = None
        self.early_stopping = None
        
    def prepare_data(self):
        """å‡†å¤‡æ•°æ®"""
        self.logger.info("å¼€å§‹å‡†å¤‡æ•°æ®...")
        
        # åˆå§‹åŒ–æ•°æ®é›†
        self.dataset = AliRecommendDataset()
        
        # å°è¯•åŠ è½½é¢„å¤„ç†æ•°æ®
        if not self.dataset.load_processed_data():
            self.logger.info("æœªæ‰¾åˆ°é¢„å¤„ç†æ•°æ®ï¼Œå¼€å§‹æ•°æ®é¢„å¤„ç†...")
            
            # åŠ è½½åŸå§‹æ•°æ®
            user_data, item_data = self.dataset.load_data()
            
            # é¢„å¤„ç†æ•°æ®
            interaction_matrix, edge_index = self.dataset.preprocess_data(behavior_types=[4])
            
            # ä¿å­˜é¢„å¤„ç†æ•°æ®
            self.dataset.save_processed_data()
        else:
            self.logger.info("æˆåŠŸåŠ è½½é¢„å¤„ç†æ•°æ®")
        
        # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        self.train_matrix, self.test_matrix = self.dataset.split_data(
            test_ratio=self.config['evaluation']['test_ratio']
        )
        
        # å°†è¾¹ç´¢å¼•ç§»åˆ°è®¾å¤‡
        self.edge_index = self.dataset.edge_index.to(self.device)
        
        self.logger.info(f"æ•°æ®å‡†å¤‡å®Œæˆ")
        self.logger.info(f"ç”¨æˆ·æ•°: {self.dataset.n_users}, ç‰©å“æ•°: {self.dataset.n_items}")
        self.logger.info(f"è®­ç»ƒäº¤äº’æ•°: {self.train_matrix.sum()}, æµ‹è¯•äº¤äº’æ•°: {self.test_matrix.sum()}")
        
    def build_model(self):
        """æ„å»ºæ¨¡å‹"""
        self.logger.info("å¼€å§‹æ„å»ºæ¨¡å‹...")
        
        model_config = self.config['model']
        
        # åˆ›å»ºæ¨¡å‹
        self.model = LightGCN(
            n_users=self.dataset.n_users,
            n_items=self.dataset.n_items,
            embedding_dim=model_config['embedding_dim'],
            n_layers=model_config['n_layers'],
            dropout=model_config['dropout']
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        self.trainer = LightGCNTrainer(self.model, self.device)
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        training_config = self.config['training']
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=training_config['learning_rate'],
            weight_decay=training_config['weight_decay']
        )
        
        # åˆ›å»ºæ—©åœæœºåˆ¶
        self.early_stopping = EarlyStopping(patience=10, min_delta=0.001)
        
        # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        self.logger.info(f"æ¨¡å‹æ„å»ºå®Œæˆ")
        self.logger.info(f"æ€»å‚æ•°æ•°: {total_params:,}")
        self.logger.info(f"å¯è®­ç»ƒå‚æ•°æ•°: {trainable_params:,}")
        
    def evaluate_model(self, interaction_matrix: np.ndarray) -> dict:
        """
        è¯„ä¼°æ¨¡å‹
        
        Args:
            interaction_matrix: æµ‹è¯•äº¤äº’çŸ©é˜µ
            
        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        self.model.eval()
        
        with torch.no_grad():
            # è·å–ç”¨æˆ·å’Œç‰©å“åµŒå…¥
            user_embeddings, item_embeddings = self.model(self.edge_index)
            
            # è·å–æ‰€æœ‰è¯„åˆ†é¢„æµ‹
            all_ratings = self.model.get_all_ratings(user_embeddings, item_embeddings)
            all_ratings = all_ratings.cpu().numpy()
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            metrics = compute_metrics(
                all_ratings, 
                interaction_matrix, 
                k=self.config['evaluation']['k']
            )
        
        return metrics
    
    def train(self, config=None):
        """è®­ç»ƒæ¨¡å‹"""
        if config:
            self.config.update(config)
            
        if self.dataset is None:
            self.prepare_data()
        
        if self.model is None:
            self.build_model()
        
        self.logger.info("å¼€å§‹è®­ç»ƒ...")
        
        training_config = self.config['training']
        best_f1 = 0.0
        best_epoch = 0
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(training_config['epochs']):
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss = self.trainer.train_epoch(
                edge_index=self.edge_index,
                interaction_matrix=self.train_matrix,
                optimizer=self.optimizer,
                batch_size=training_config['batch_size'],
                n_batches=100
            )
            
            # æ¯10ä¸ªepochè¯„ä¼°ä¸€æ¬¡
            if (epoch + 1) % 10 == 0:
                # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
                test_metrics = self.evaluate_model(self.test_matrix)
                
                self.logger.info(
                    f"Epoch {epoch+1}/{training_config['epochs']} - "
                    f"Train Loss: {train_loss:.4f}, "
                    f"Test F1: {test_metrics['f1']:.4f}"
                )
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if test_metrics['f1'] > best_f1:
                    best_f1 = test_metrics['f1']
                    best_epoch = epoch + 1
                    self.save_model('best_model.pt')
                    self.logger.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹ (F1: {best_f1:.4f})")
                
                # æ—©åœæ£€æŸ¥
                self.early_stopping(test_metrics['f1'])
                if self.early_stopping.early_stop:
                    self.logger.info(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
                    break
            else:
                if (epoch + 1) % 5 == 0:
                    self.logger.info(f"Epoch {epoch+1}/{training_config['epochs']} - Train Loss: {train_loss:.4f}")
        
        self.logger.info(f"è®­ç»ƒå®Œæˆï¼æœ€ä½³F1åˆ†æ•°: {best_f1:.4f} (ç¬¬ {best_epoch} è½®)")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆè¯„ä¼°
        self.load_model('best_model.pt')
        final_metrics = self.evaluate_model(self.test_matrix)
        
        self.logger.info("æœ€ç»ˆæµ‹è¯•ç»“æœ:")
        self.logger.info(f"Precision: {final_metrics['precision']:.4f}")
        self.logger.info(f"Recall: {final_metrics['recall']:.4f}")
        self.logger.info(f"F1-Score: {final_metrics['f1']:.4f}")
        
        return final_metrics
    
    def save_model(self, filename: str):
        """ä¿å­˜æ¨¡å‹"""
        model_dir = 'outputs/models'
        os.makedirs(model_dir, exist_ok=True)
        
        model_path = os.path.join(model_dir, filename)
        
        # ä¿å­˜æ¨¡å‹çŠ¶æ€å’Œç›¸å…³ä¿¡æ¯
        checkpoint = {
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'config': self.config,
            'n_users': self.dataset.n_users,
            'n_items': self.dataset.n_items,
            'user_mapping': self.dataset.user_mapping,
            'item_mapping': self.dataset.item_mapping
        }
        
        torch.save(checkpoint, model_path)
        self.logger.info(f"æ¨¡å‹å·²ä¿å­˜è‡³: {model_path}")
    
    def load_model(self, filename: str):
        """åŠ è½½æ¨¡å‹"""
        model_dir = 'outputs/models'
        model_path = os.path.join(model_dir, filename)
        
        if os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location=self.device)
            
            # å¦‚æœæ¨¡å‹æœªåˆå§‹åŒ–ï¼Œå…ˆåˆå§‹åŒ–
            if self.model is None:
                model_config = checkpoint['config']['model']
                self.model = LightGCN(
                    n_users=checkpoint['n_users'],
                    n_items=checkpoint['n_items'],
                    embedding_dim=model_config['embedding_dim'],
                    n_layers=model_config['n_layers'],
                    dropout=model_config['dropout']
                )
                self.model.to(self.device)
            
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.logger.info(f"æ¨¡å‹å·²ä» {model_path} åŠ è½½")
            return True
        else:
            self.logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
    
    def generate_recommendations(self, user_ids: list = None, k: int = 20):
        """
        ç”Ÿæˆæ¨èç»“æœ
        
        Args:
            user_ids: ç”¨æˆ·IDåˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä¸ºæ‰€æœ‰ç”¨æˆ·ç”Ÿæˆæ¨è
            k: æ¨èæ•°é‡
            
        Returns:
            æ¨èç»“æœåˆ—è¡¨ [(original_user_id, original_item_id), ...]
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè®­ç»ƒæˆ–åŠ è½½æ¨¡å‹")
        
        self.model.eval()
        recommendations = []
        
        # åˆ›å»ºåå‘æ˜ å°„
        reverse_user_mapping = {v: k for k, v in self.dataset.user_mapping.items()}
        reverse_item_mapping = {v: k for k, v in self.dataset.item_mapping.items()}
        
        with torch.no_grad():
            # è·å–ç”¨æˆ·å’Œç‰©å“åµŒå…¥
            user_embeddings, item_embeddings = self.model(self.edge_index)
            
            # å¦‚æœæœªæŒ‡å®šç”¨æˆ·ï¼Œä¸ºæ‰€æœ‰ç”¨æˆ·ç”Ÿæˆæ¨è
            if user_ids is None:
                user_indices = list(range(self.dataset.n_users))
            else:
                user_indices = [self.dataset.user_mapping[uid] for uid in user_ids 
                              if uid in self.dataset.user_mapping]
            
            for user_idx in user_indices:
                # ä¸ºç”¨æˆ·ç”Ÿæˆæ¨è
                recommended_items = self.model.recommend(user_idx, user_embeddings, item_embeddings, k)
                
                # è½¬æ¢å›åŸå§‹ID
                original_user_id = reverse_user_mapping[user_idx]
                
                for item_idx in recommended_items.cpu().numpy():
                    original_item_id = reverse_item_mapping[item_idx]
                    recommendations.append((original_user_id, original_item_id))
        
        return recommendations


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='LightGCNæ¨¡å‹è®­ç»ƒ')
    parser.add_argument('--config', type=str, default='config.json',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--epochs', type=int, default=None,
                       help='è®­ç»ƒè½®æ•°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--batch-size', type=int, default=None,
                       help='æ‰¹æ¬¡å¤§å°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--learning-rate', type=float, default=None,
                       help='å­¦ä¹ ç‡ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--embedding-dim', type=int, default=None,
                       help='åµŒå…¥ç»´åº¦ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹LightGCNæ¨¡å‹è®­ç»ƒ...")
    
    # åˆ›å»ºè®­ç»ƒç®¡é“
    pipeline = LightGCNTrainingPipeline(args.config)
    
    # è¦†ç›–é…ç½®å‚æ•°
    config_override = {}
    if args.epochs is not None:
        config_override.setdefault('training', {})['epochs'] = args.epochs
    if args.batch_size is not None:
        config_override.setdefault('training', {})['batch_size'] = args.batch_size
    if args.learning_rate is not None:
        config_override.setdefault('training', {})['learning_rate'] = args.learning_rate
    if args.embedding_dim is not None:
        config_override.setdefault('model', {})['embedding_dim'] = args.embedding_dim
    
    try:
        # è®­ç»ƒæ¨¡å‹
        print(f"ğŸ“Š ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
        if config_override:
            print(f"ğŸ”§ å‚æ•°è¦†ç›–: {config_override}")
            
        final_metrics = pipeline.train(config_override)
        
        print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“ˆ æœ€ç»ˆæŒ‡æ ‡:")
        print(f"  - Precision: {final_metrics['precision']:.4f}")
        print(f"  - Recall: {final_metrics['recall']:.4f}")
        print(f"  - F1-Score: {final_metrics['f1']:.4f}")
        
        # ç”Ÿæˆæ¨èç»“æœç¤ºä¾‹
        print("\nğŸ¯ ç”Ÿæˆæ¨èç»“æœç¤ºä¾‹...")
        sample_recommendations = pipeline.generate_recommendations(k=5)
        
        print(f"ä¸ºå‰3ä¸ªç”¨æˆ·ç”Ÿæˆçš„æ¨èç»“æœ:")
        current_user = None
        count = 0
        for user_id, item_id in sample_recommendations[:15]:
            if user_id != current_user:
                if count >= 3:
                    break
                current_user = user_id
                count += 1
                print(f"\nğŸ‘¤ ç”¨æˆ· {user_id} çš„æ¨è:")
            print(f"  - ç‰©å“ {item_id}")
        
        print("\nâœ… è®­ç»ƒå’Œæ¨èç”Ÿæˆå®Œæˆï¼")
        print("ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°: outputs/models/best_model.pt")
        print("ğŸ”„ è½¬æ¢ONNX: python service/convert_to_onnx.py --model-path outputs/models/best_model.pt")
        print("ğŸš€ å¯åŠ¨æœåŠ¡: python service/onnx_server.py --model-path outputs/models/best_model.onnx")
        print("ğŸ¨ å¯åŠ¨ç•Œé¢: python run_app.py")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise
    
    return 0


if __name__ == "__main__":
    main()