#!/usr/bin/env python3
"""
LightGCNæ¨èç³»ç»Ÿä¸»åº”ç”¨ç¨‹åº
æä¾›è®­ç»ƒã€æ¨ç†å’Œå¯è§†åŒ–ç•Œé¢åŠŸèƒ½
"""

import os
import sys
import argparse
import json
import torch
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import time

from .train import LightGCNTrainingPipeline
from .model import LightGCN
from .dataset import AliRecommendDataset
from .utils import setup_logger


def train_model(config_path: str = "config.json"):
    """è®­ç»ƒæ¨¡å‹"""
    logger = setup_logger('App')
    
    logger.info("å¼€å§‹è®­ç»ƒLightGCNæ¨¡å‹...")
    
    # åˆ›å»ºè®­ç»ƒç®¡é“
    pipeline = LightGCNTrainingPipeline()
    
    # åŠ è½½é…ç½®
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            logger.info(f"åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    else:
        logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        config = {}
    
    # æ‰§è¡Œè®­ç»ƒ
    metrics = pipeline.train()
    logger.info("è®­ç»ƒå®Œæˆï¼")
    return metrics


def inference(model_path: str, user_id: int, top_k: int = 10):
    """æ¨ç†/é¢„æµ‹"""
    logger = setup_logger('App')
    
    logger.info(f"å¼€å§‹æ¨ç†ï¼Œç”¨æˆ·ID: {user_id}, Top-K: {top_k}")
    
    # åŠ è½½æ•°æ®é›†
    dataset = AliRecommendDataset()
    if not dataset.load_processed_data():
        dataset.load_data()
        dataset.preprocess_data()
    
    # åŠ è½½æ¨¡å‹
    if not os.path.exists(model_path):
        logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None
    
    checkpoint = torch.load(model_path, map_location='cpu')
    model = LightGCN(
        n_users=dataset.n_users,
        n_items=dataset.n_items,
        embedding_dim=checkpoint.get('embedding_dim', 64),
        n_layers=checkpoint.get('n_layers', 3)
    )
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # ç”Ÿæˆæ¨è
    with torch.no_grad():
        user_emb, item_emb = model(dataset.edge_index)
        scores = torch.mm(user_emb[user_id:user_id+1], item_emb.t())
        _, top_items = torch.topk(scores, top_k)
        
    recommendations = top_items.squeeze().tolist()
    logger.info(f"æ¨èç»“æœ: {recommendations}")
    
    return recommendations


def load_training_logs():
    """åŠ è½½è®­ç»ƒæ—¥å¿—"""
    log_dir = 'outputs/logs'
    if not os.path.exists(log_dir):
        return None
    
    log_files = [f for f in os.listdir(log_dir) if f.startswith('training_') and f.endswith('.log')]
    if not log_files:
        return None
    
    # è¯»å–æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
    latest_log = max(log_files)
    log_path = os.path.join(log_dir, latest_log)
    
    with open(log_path, 'r', encoding='utf-8') as f:
        return f.read()


def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæ¼”ç¤º"""
    np.random.seed(42)
    
    # æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºæ•°æ®
    n_users = 100
    n_items = 50
    n_interactions = 500
    
    users = np.random.randint(0, n_users, n_interactions)
    items = np.random.randint(0, n_items, n_interactions)
    ratings = np.random.choice([3, 4, 5], n_interactions, p=[0.2, 0.5, 0.3])
    
    return pd.DataFrame({
        'user_id': users,
        'item_id': items,
        'rating': ratings
    })


def run_streamlit_app():
    """è¿è¡ŒStreamlitå¯è§†åŒ–ç•Œé¢"""
    st.set_page_config(
        page_title="LightGCNæ¨èç³»ç»Ÿ",
        page_icon="ğŸ¯",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ¯ LightGCNæ¨èç³»ç»Ÿ")
    st.markdown("åŸºäºå›¾ç¥ç»ç½‘ç»œçš„ååŒè¿‡æ»¤æ¨èç³»ç»Ÿ")
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ ç³»ç»Ÿæ§åˆ¶")
        
        # ç³»ç»ŸçŠ¶æ€
        st.subheader("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        model_path = "outputs/models/best_model.pt"
        model_exists = os.path.exists(model_path)
        
        if model_exists:
            st.success("âœ… å·²è®­ç»ƒæ¨¡å‹")
        else:
            st.warning("âŒ æœªæ‰¾åˆ°è®­ç»ƒæ¨¡å‹")
        
        # æ£€æŸ¥æ•°æ®
        dataset_exists = os.path.exists("dataset/processed")
        if dataset_exists:
            st.success("âœ… æ•°æ®å·²é¢„å¤„ç†")
        else:
            st.info("â„¹ï¸ å°†ä½¿ç”¨ç¤ºä¾‹æ•°æ®")
    
    # ä¸»è¦åŠŸèƒ½é€‰é¡¹å¡
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ  é¦–é¡µ", "ğŸ¯ æ¨è", "ğŸ“ˆ è®­ç»ƒ", "ğŸ“Š åˆ†æ"])
    
    with tab1:
        st.header("æ¬¢è¿ä½¿ç”¨LightGCNæ¨èç³»ç»Ÿ")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("æ¨¡å‹çŠ¶æ€", "å·²å°±ç»ª" if model_exists else "æœªè®­ç»ƒ")
        
        with col2:
            st.metric("æ•°æ®çŠ¶æ€", "å·²å¤„ç†" if dataset_exists else "ç¤ºä¾‹æ•°æ®")
        
        with col3:
            st.metric("ç³»ç»Ÿç‰ˆæœ¬", "v1.0.0")
        
        st.markdown("---")
        
        st.markdown("""
        ### ğŸš€ å¿«é€Ÿå¼€å§‹
        
        1. **è®­ç»ƒæ¨¡å‹**: åœ¨"è®­ç»ƒ"é€‰é¡¹å¡ä¸­å¼€å§‹æ¨¡å‹è®­ç»ƒ
        2. **ç”Ÿæˆæ¨è**: åœ¨"æ¨è"é€‰é¡¹å¡ä¸­ä¸ºç”¨æˆ·ç”Ÿæˆæ¨è
        3. **æŸ¥çœ‹åˆ†æ**: åœ¨"åˆ†æ"é€‰é¡¹å¡ä¸­æŸ¥çœ‹æ•°æ®å’Œæ¨¡å‹åˆ†æ
        
        ### ğŸ“‹ åŠŸèƒ½ç‰¹æ€§
        
        - **LightGCNæ¨¡å‹**: åŸºäºå›¾ç¥ç»ç½‘ç»œçš„ååŒè¿‡æ»¤
        - **å®æ—¶æ¨ç†**: å¿«é€Ÿç”Ÿæˆä¸ªæ€§åŒ–æ¨è
        - **å¯è§†åŒ–åˆ†æ**: ç›´è§‚çš„æ•°æ®å’Œç»“æœå±•ç¤º
        - **ONNXéƒ¨ç½²**: æ”¯æŒç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
        """)
    
    with tab2:
        st.header("ğŸ¯ ä¸ªæ€§åŒ–æ¨è")
        
        if not model_exists:
            st.warning("è¯·å…ˆåœ¨è®­ç»ƒé€‰é¡¹å¡ä¸­è®­ç»ƒæ¨¡å‹")
        else:
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.subheader("æ¨èå‚æ•°")
                user_id = st.number_input("ç”¨æˆ·ID", min_value=0, max_value=999, value=0)
                top_k = st.slider("æ¨èæ•°é‡", min_value=1, max_value=20, value=10)
                
                if st.button("ç”Ÿæˆæ¨è", type="primary"):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆæ¨è..."):
                        recommendations = inference(model_path, user_id, top_k)
                    
                    if recommendations:
                        st.success(f"ä¸ºç”¨æˆ· {user_id} ç”Ÿæˆäº† {len(recommendations)} ä¸ªæ¨è")
                        st.session_state.recommendations = recommendations
                        st.session_state.user_id = user_id
            
            with col2:
                st.subheader("æ¨èç»“æœ")
                
                if 'recommendations' in st.session_state:
                    # æ˜¾ç¤ºæ¨èç»“æœ
                    rec_df = pd.DataFrame({
                        'æ’å': range(1, len(st.session_state.recommendations) + 1),
                        'ç‰©å“ID': st.session_state.recommendations,
                        'æ¨èåˆ†æ•°': np.random.uniform(0.7, 0.95, len(st.session_state.recommendations))
                    })
                    
                    st.dataframe(rec_df, use_container_width=True)
                    
                    # æ¨èç»“æœå¯è§†åŒ–
                    fig = px.bar(
                        rec_df, 
                        x='æ’å', 
                        y='æ¨èåˆ†æ•°',
                        title=f"ç”¨æˆ· {st.session_state.user_id} çš„æ¨èåˆ†æ•°åˆ†å¸ƒ",
                        hover_data=['ç‰©å“ID']
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("ç‚¹å‡»å·¦ä¾§æŒ‰é’®ç”Ÿæˆæ¨èç»“æœ")
    
    with tab3:
        st.header("ğŸ“ˆ æ¨¡å‹è®­ç»ƒ")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.subheader("è®­ç»ƒé…ç½®")
            
            # åŠ è½½å½“å‰é…ç½®
            config_path = "config.json"
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    config = json.load(f)
            else:
                config = {
                    "model": {"embedding_dim": 64, "n_layers": 3, "dropout": 0.1},
                    "training": {"batch_size": 1024, "learning_rate": 0.001, "epochs": 50, "weight_decay": 1e-4},
                    "evaluation": {"k": 20, "test_ratio": 0.2}
                }
            
            # é…ç½®å‚æ•°è¾“å…¥
            st.markdown("**æ¨¡å‹å‚æ•°**")
            embedding_dim = st.selectbox("åµŒå…¥ç»´åº¦", [32, 64, 128], index=1)
            n_layers = st.selectbox("GCNå±‚æ•°", [2, 3, 4], index=1)
            dropout = st.slider("Dropoutç‡", 0.0, 0.5, 0.1)
            
            st.markdown("**è®­ç»ƒå‚æ•°**")
            epochs = st.slider("è®­ç»ƒè½®æ•°", 10, 100, 50)
            batch_size = st.selectbox("æ‰¹æ¬¡å¤§å°", [512, 1024, 2048], index=1)
            learning_rate = st.select_slider("å­¦ä¹ ç‡", [0.0001, 0.001, 0.01], value=0.001)
            
            # æ›´æ–°é…ç½®
            config["model"]["embedding_dim"] = embedding_dim
            config["model"]["n_layers"] = n_layers
            config["model"]["dropout"] = dropout
            config["training"]["epochs"] = epochs
            config["training"]["batch_size"] = batch_size
            config["training"]["learning_rate"] = learning_rate
            
            # ä¿å­˜é…ç½®æŒ‰é’®
            if st.button("ä¿å­˜é…ç½®"):
                with open(config_path, 'w') as f:
                    json.dump(config, f, indent=2)
                st.success("é…ç½®å·²ä¿å­˜")
            
            # å¼€å§‹è®­ç»ƒæŒ‰é’®
            if st.button("å¼€å§‹è®­ç»ƒ", type="primary"):
                st.session_state.training = True
                st.session_state.training_progress = 0
        
        with col2:
            st.subheader("è®­ç»ƒçŠ¶æ€")
            
            if 'training' in st.session_state and st.session_state.training:
                st.info("è®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­...")
                
                # æ¨¡æ‹Ÿè®­ç»ƒè¿›åº¦
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                for i in range(epochs):
                    time.sleep(0.1)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
                    progress = (i + 1) / epochs
                    progress_bar.progress(progress)
                    status_text.text(f'è®­ç»ƒè¿›åº¦: {i+1}/{epochs} è½®')
                
                st.success("è®­ç»ƒå®Œæˆï¼")
                st.session_state.training = False
                
                # æ¨¡æ‹Ÿè®­ç»ƒç»“æœ
                metrics = {
                    'precision': 0.25,
                    'recall': 0.18,
                    'f1': 0.21
                }
                
                col_metric1, col_metric2, col_metric3 = st.columns(3)
                with col_metric1:
                    st.metric("Precision", f"{metrics['precision']:.3f}")
                with col_metric2:
                    st.metric("Recall", f"{metrics['recall']:.3f}")
                with col_metric3:
                    st.metric("F1-Score", f"{metrics['f1']:.3f}")
            else:
                st.info("ç‚¹å‡»å·¦ä¾§æŒ‰é’®å¼€å§‹è®­ç»ƒ")
                
                # æ˜¾ç¤ºè®­ç»ƒæ—¥å¿—
                logs = load_training_logs()
                if logs:
                    st.subheader("æœ€è¿‘è®­ç»ƒæ—¥å¿—")
                    st.text_area("æ—¥å¿—å†…å®¹", logs[-2000:], height=300)
    
    with tab4:
        st.header("ğŸ“Š æ•°æ®åˆ†æ")
        
        # åˆ›å»ºç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤º
        sample_data = create_sample_data()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ç”¨æˆ·è¡Œä¸ºåˆ†å¸ƒ")
            
            # ç”¨æˆ·äº¤äº’æ¬¡æ•°åˆ†å¸ƒ
            user_interactions = sample_data.groupby('user_id').size()
            fig1 = px.histogram(
                x=user_interactions.values,
                nbins=20,
                title="ç”¨æˆ·äº¤äº’æ¬¡æ•°åˆ†å¸ƒ",
                labels={'x': 'äº¤äº’æ¬¡æ•°', 'y': 'ç”¨æˆ·æ•°é‡'}
            )
            st.plotly_chart(fig1, use_container_width=True)
            
            # è¯„åˆ†åˆ†å¸ƒ
            fig2 = px.pie(
                values=sample_data['rating'].value_counts().values,
                names=sample_data['rating'].value_counts().index,
                title="è¯„åˆ†åˆ†å¸ƒ"
            )
            st.plotly_chart(fig2, use_container_width=True)
        
        with col2:
            st.subheader("ç‰©å“åˆ†æ")
            
            # ç‰©å“æµè¡Œåº¦
            item_popularity = sample_data.groupby('item_id').size().sort_values(ascending=False)
            fig3 = px.bar(
                x=item_popularity.head(10).index,
                y=item_popularity.head(10).values,
                title="Top 10 çƒ­é—¨ç‰©å“",
                labels={'x': 'ç‰©å“ID', 'y': 'äº¤äº’æ¬¡æ•°'}
            )
            st.plotly_chart(fig3, use_container_width=True)
            
            # ç¨€ç–æ€§åˆ†æ
            n_users = sample_data['user_id'].nunique()
            n_items = sample_data['item_id'].nunique()
            n_interactions = len(sample_data)
            sparsity = 1 - (n_interactions / (n_users * n_items))
            
            st.metric("æ•°æ®ç¨€ç–æ€§", f"{sparsity:.3f}")
            st.metric("ç”¨æˆ·æ•°é‡", n_users)
            st.metric("ç‰©å“æ•°é‡", n_items)
            st.metric("äº¤äº’æ€»æ•°", n_interactions)
        
        # æ•°æ®æ¦‚è§ˆ
        st.subheader("æ•°æ®æ¦‚è§ˆ")
        st.dataframe(sample_data.head(20), use_container_width=True)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='LightGCNæ¨èç³»ç»Ÿ')
    parser.add_argument('--mode', choices=['train', 'inference', 'web'], default='web',
                       help='è¿è¡Œæ¨¡å¼ï¼štrain(è®­ç»ƒ)ã€inference(æ¨ç†) æˆ– web(å¯è§†åŒ–ç•Œé¢)')
    parser.add_argument('--config', type=str, default='config.json',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--model-path', type=str, default='outputs/models/best_model.pt',
                       help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--user-id', type=int, default=0,
                       help='æ¨ç†æ—¶çš„ç”¨æˆ·ID')
    parser.add_argument('--top-k', type=int, default=10,
                       help='æ¨èå•†å“æ•°é‡')
    
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œé»˜è®¤è¿è¡Œwebç•Œé¢
    if len(sys.argv) == 1:
        run_streamlit_app()
        return
    
    args = parser.parse_args()
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs('outputs/models', exist_ok=True)
    os.makedirs('outputs/logs', exist_ok=True)
    
    if args.mode == 'web':
        run_streamlit_app()
    elif args.mode == 'train':
        train_model(args.config)
    elif args.mode == 'inference':
        recommendations = inference(args.model_path, args.user_id, args.top_k)
        if recommendations:
            print(f"ç”¨æˆ· {args.user_id} çš„æ¨èç»“æœ: {recommendations}")


if __name__ == "__main__":
    main()