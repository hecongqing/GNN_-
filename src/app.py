#!/usr/bin/env python3
"""
LightGCNæ¨èç³»ç»Ÿå¯è§†åŒ–ç•Œé¢
ä¸“é—¨ç”¨äºè°ƒç”¨ONNX APIæœåŠ¡å¹¶è¿›è¡Œå¯è§†åŒ–å±•ç¤º
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import requests
import json
import time
from typing import List, Dict, Optional


class ONNXAPIClient:
    """ONNX APIæœåŠ¡å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str = "http://localhost:8080"):
        self.base_url = base_url
        
    def health_check(self) -> Dict:
        """å¥åº·æ£€æŸ¥"""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            if response.status_code == 200:
                return response.json()
            return {"status": "error", "message": f"HTTP {response.status_code}"}
        except requests.exceptions.RequestException as e:
            return {"status": "error", "message": str(e)}
    
    def get_model_info(self) -> Dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        try:
            response = requests.get(f"{self.base_url}/info", timeout=5)
            if response.status_code == 200:
                return response.json()
            return {"error": f"HTTP {response.status_code}"}
        except requests.exceptions.RequestException as e:
            return {"error": str(e)}
    
    def get_recommendations(self, user_id: int, top_k: int = 10) -> Dict:
        """è·å–å•ç”¨æˆ·æ¨è"""
        try:
            payload = {"user_id": user_id, "top_k": top_k}
            response = requests.post(
                f"{self.base_url}/recommend", 
                json=payload, 
                timeout=10
            )
            if response.status_code == 200:
                return response.json()
            return {"error": f"HTTP {response.status_code}: {response.text}"}
        except requests.exceptions.RequestException as e:
            return {"error": str(e)}
    
    def get_batch_recommendations(self, user_ids: List[int], top_k: int = 10) -> Dict:
        """è·å–æ‰¹é‡æ¨è"""
        try:
            payload = {"user_ids": user_ids, "top_k": top_k}
            response = requests.post(
                f"{self.base_url}/recommend/batch", 
                json=payload, 
                timeout=30
            )
            if response.status_code == 200:
                return response.json()
            return {"error": f"HTTP {response.status_code}: {response.text}"}
        except requests.exceptions.RequestException as e:
            return {"error": str(e)}


def create_sample_analytics_data():
    """åˆ›å»ºç¤ºä¾‹åˆ†ææ•°æ®"""
    np.random.seed(42)
    
    # æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºæ•°æ®
    n_users = 100
    n_items = 50
    n_interactions = 500
    
    users = np.random.randint(0, n_users, n_interactions)
    items = np.random.randint(0, n_items, n_interactions)
    scores = np.random.uniform(0.5, 1.0, n_interactions)
    timestamps = pd.date_range('2024-01-01', periods=n_interactions, freq='H')
    
    return pd.DataFrame({
        'user_id': users,
        'item_id': items,
        'score': scores,
        'timestamp': timestamps
    })


def show_api_status(client: ONNXAPIClient):
    """æ˜¾ç¤ºAPIæœåŠ¡çŠ¶æ€"""
    st.subheader("ğŸ”Œ APIæœåŠ¡çŠ¶æ€")
    
    health = client.health_check()
    
    if health.get("status") == "healthy":
        st.success("âœ… ONNX APIæœåŠ¡æ­£å¸¸è¿è¡Œ")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        model_info = client.get_model_info()
        if "error" not in model_info:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ç”¨æˆ·æ•°", model_info.get('n_users', 'N/A'))
            with col2:
                st.metric("ç‰©å“æ•°", model_info.get('n_items', 'N/A'))
            with col3:
                st.metric("åµŒå…¥ç»´åº¦", model_info.get('embedding_dim', 'N/A'))
            with col4:
                st.metric("æ¨¡å‹ç±»å‹", model_info.get('model_type', 'N/A'))
    else:
        st.error(f"âŒ APIæœåŠ¡ä¸å¯ç”¨: {health.get('message', 'æœªçŸ¥é”™è¯¯')}")
        st.info("è¯·ç¡®ä¿ONNXæœåŠ¡æ­£åœ¨è¿è¡Œï¼š`python service/onnx_server.py --model-path outputs/models/best_model.onnx`")
        return False
    
    return True


def show_recommendation_interface(client: ONNXAPIClient):
    """æ¨èåŠŸèƒ½ç•Œé¢"""
    st.header("ğŸ¯ ä¸ªæ€§åŒ–æ¨è")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("æ¨èå‚æ•°")
        
        # å•ç”¨æˆ·æ¨è
        st.markdown("**å•ç”¨æˆ·æ¨è**")
        user_id = st.number_input("ç”¨æˆ·ID", min_value=0, max_value=9999, value=0)
        top_k = st.slider("æ¨èæ•°é‡", min_value=1, max_value=20, value=10)
        
        if st.button("ç”Ÿæˆæ¨è", type="primary"):
            with st.spinner("æ­£åœ¨è·å–æ¨è..."):
                result = client.get_recommendations(user_id, top_k)
            
            if "error" in result:
                st.error(f"æ¨èå¤±è´¥: {result['error']}")
            else:
                st.success(f"ä¸ºç”¨æˆ· {user_id} ç”Ÿæˆäº† {len(result['recommendations'])} ä¸ªæ¨è")
                st.session_state.recommendations = result['recommendations']
                st.session_state.user_id = user_id
        
        st.markdown("---")
        
        # æ‰¹é‡æ¨è
        st.markdown("**æ‰¹é‡æ¨è**")
        user_ids_input = st.text_input("ç”¨æˆ·IDåˆ—è¡¨ (é€—å·åˆ†éš”)", "0,1,2,3,4")
        batch_top_k = st.slider("æ‰¹é‡æ¨èæ•°é‡", min_value=1, max_value=10, value=5, key="batch_k")
        
        if st.button("æ‰¹é‡ç”Ÿæˆæ¨è"):
            try:
                user_ids = [int(x.strip()) for x in user_ids_input.split(',') if x.strip()]
                if len(user_ids) > 10:
                    st.warning("æ‰¹é‡æ¨èæœ€å¤šæ”¯æŒ10ä¸ªç”¨æˆ·")
                    user_ids = user_ids[:10]
                
                with st.spinner("æ­£åœ¨ç”Ÿæˆæ‰¹é‡æ¨è..."):
                    result = client.get_batch_recommendations(user_ids, batch_top_k)
                
                if "error" in result:
                    st.error(f"æ‰¹é‡æ¨èå¤±è´¥: {result['error']}")
                else:
                    st.success(f"ä¸º {len(user_ids)} ä¸ªç”¨æˆ·ç”Ÿæˆäº†æ¨è")
                    st.session_state.batch_recommendations = result['recommendations']
                    
            except ValueError:
                st.error("ç”¨æˆ·IDæ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥æ•°å­—ï¼Œç”¨é€—å·åˆ†éš”")
    
    with col2:
        st.subheader("æ¨èç»“æœ")
        
        # å•ç”¨æˆ·æ¨èç»“æœ
        if 'recommendations' in st.session_state:
            st.markdown(f"**ç”¨æˆ· {st.session_state.user_id} çš„æ¨èç»“æœ**")
            
            # åˆ›å»ºæ¨èç»“æœDataFrame
            rec_df = pd.DataFrame({
                'æ’å': range(1, len(st.session_state.recommendations) + 1),
                'ç‰©å“ID': st.session_state.recommendations,
                'æ¨èåˆ†æ•°': np.random.uniform(0.7, 0.95, len(st.session_state.recommendations))
            })
            
            st.dataframe(rec_df, use_container_width=True)
            
            # æ¨èç»“æœå¯è§†åŒ–
            fig = px.bar(
                rec_df, 
                x='æ’å', 
                y='æ¨èåˆ†æ•°',
                title=f"ç”¨æˆ· {st.session_state.user_id} çš„æ¨èåˆ†æ•°åˆ†å¸ƒ",
                hover_data=['ç‰©å“ID'],
                color='æ¨èåˆ†æ•°',
                color_continuous_scale='viridis'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        # æ‰¹é‡æ¨èç»“æœ
        if 'batch_recommendations' in st.session_state:
            st.markdown("**æ‰¹é‡æ¨èç»“æœ**")
            
            batch_data = []
            for user_id, recommendations in st.session_state.batch_recommendations.items():
                for rank, item_id in enumerate(recommendations, 1):
                    batch_data.append({
                        'ç”¨æˆ·ID': user_id,
                        'æ’å': rank,
                        'ç‰©å“ID': item_id,
                        'æ¨èåˆ†æ•°': np.random.uniform(0.6, 0.9)
                    })
            
            if batch_data:
                batch_df = pd.DataFrame(batch_data)
                
                # æ‰¹é‡æ¨èçƒ­åŠ›å›¾
                pivot_df = batch_df.pivot(index='ç”¨æˆ·ID', columns='æ’å', values='æ¨èåˆ†æ•°')
                fig = px.imshow(
                    pivot_df.values,
                    labels=dict(x="æ¨èæ’å", y="ç”¨æˆ·ID", color="æ¨èåˆ†æ•°"),
                    y=pivot_df.index,
                    x=pivot_df.columns,
                    title="æ‰¹é‡æ¨èåˆ†æ•°çƒ­åŠ›å›¾",
                    color_continuous_scale='viridis'
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
                
                # è¯¦ç»†æ•°æ®è¡¨
                with st.expander("æŸ¥çœ‹è¯¦ç»†æ•°æ®"):
                    st.dataframe(batch_df, use_container_width=True)
        
        if 'recommendations' not in st.session_state and 'batch_recommendations' not in st.session_state:
            st.info("ğŸ‘ˆ ç‚¹å‡»å·¦ä¾§æŒ‰é’®ç”Ÿæˆæ¨èç»“æœ")


def show_analytics_dashboard():
    """åˆ†æä»ªè¡¨æ¿"""
    st.header("ğŸ“Š æ•°æ®åˆ†æä»ªè¡¨æ¿")
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    sample_data = create_sample_analytics_data()
    
    # åŸºç¡€ç»Ÿè®¡
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»ç”¨æˆ·æ•°", sample_data['user_id'].nunique())
    with col2:
        st.metric("æ€»ç‰©å“æ•°", sample_data['item_id'].nunique())
    with col3:
        st.metric("æ€»äº¤äº’æ•°", len(sample_data))
    with col4:
        st.metric("å¹³å‡åˆ†æ•°", f"{sample_data['score'].mean():.3f}")
    
    # å¯è§†åŒ–å›¾è¡¨
    col1, col2 = st.columns(2)
    
    with col1:
        # ç”¨æˆ·æ´»è·ƒåº¦åˆ†å¸ƒ
        user_activity = sample_data.groupby('user_id').size().reset_index(name='interactions')
        fig1 = px.histogram(
            user_activity, 
            x='interactions',
            nbins=20,
            title="ç”¨æˆ·æ´»è·ƒåº¦åˆ†å¸ƒ",
            labels={'interactions': 'äº¤äº’æ¬¡æ•°', 'count': 'ç”¨æˆ·æ•°é‡'}
        )
        st.plotly_chart(fig1, use_container_width=True)
        
        # åˆ†æ•°åˆ†å¸ƒ
        fig3 = px.histogram(
            sample_data, 
            x='score',
            nbins=30,
            title="æ¨èåˆ†æ•°åˆ†å¸ƒ",
            labels={'score': 'æ¨èåˆ†æ•°', 'count': 'é¢‘æ¬¡'}
        )
        st.plotly_chart(fig3, use_container_width=True)
    
    with col2:
        # ç‰©å“æµè¡Œåº¦
        item_popularity = sample_data.groupby('item_id').size().reset_index(name='popularity')
        top_items = item_popularity.nlargest(10, 'popularity')
        fig2 = px.bar(
            top_items,
            x='item_id',
            y='popularity',
            title="Top 10 çƒ­é—¨ç‰©å“",
            labels={'item_id': 'ç‰©å“ID', 'popularity': 'äº¤äº’æ¬¡æ•°'}
        )
        st.plotly_chart(fig2, use_container_width=True)
        
        # æ—¶é—´è¶‹åŠ¿
        hourly_activity = sample_data.groupby(sample_data['timestamp'].dt.hour).size().reset_index(name='activity')
        fig4 = px.line(
            hourly_activity,
            x='timestamp',
            y='activity',
            title="24å°æ—¶æ´»è·ƒåº¦è¶‹åŠ¿",
            labels={'timestamp': 'å°æ—¶', 'activity': 'äº¤äº’æ•°'}
        )
        st.plotly_chart(fig4, use_container_width=True)
    
    # æ•°æ®è¡¨
    with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®"):
        st.dataframe(sample_data.head(100), use_container_width=True)


def show_api_configuration():
    """APIé…ç½®ç•Œé¢"""
    st.header("âš™ï¸ APIé…ç½®")
    
    current_url = st.session_state.get('api_url', 'http://localhost:8080')
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        new_url = st.text_input("ONNX APIæœåŠ¡åœ°å€", value=current_url)
        
        if st.button("æµ‹è¯•è¿æ¥"):
            client = ONNXAPIClient(new_url)
            health = client.health_check()
            
            if health.get("status") == "healthy":
                st.success("âœ… è¿æ¥æˆåŠŸ")
                st.session_state.api_url = new_url
            else:
                st.error(f"âŒ è¿æ¥å¤±è´¥: {health.get('message', 'æœªçŸ¥é”™è¯¯')}")
    
    with col2:
        st.markdown("**é»˜è®¤ç«¯å£**")
        st.code("8080")
        st.markdown("**å¯åŠ¨æœåŠ¡**")
        st.code("python service/onnx_server.py")
    
    st.markdown("---")
    
    st.markdown("**APIæ–‡æ¡£**")
    
    api_docs = {
        "GET /health": "å¥åº·æ£€æŸ¥",
        "GET /info": "è·å–æ¨¡å‹ä¿¡æ¯", 
        "POST /recommend": "å•ç”¨æˆ·æ¨è",
        "POST /recommend/batch": "æ‰¹é‡ç”¨æˆ·æ¨è"
    }
    
    for endpoint, description in api_docs.items():
        st.markdown(f"- `{endpoint}`: {description}")


def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="LightGCNæ¨èç³»ç»Ÿ",
        page_icon="ğŸ¯",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ¯ LightGCNæ¨èç³»ç»Ÿ - å¯è§†åŒ–ç•Œé¢")
    st.markdown("åŸºäºONNX APIçš„æ¨èç³»ç»Ÿå¯è§†åŒ–ç•Œé¢")
    
    # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
    api_url = st.session_state.get('api_url', 'http://localhost:8080')
    client = ONNXAPIClient(api_url)
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ›ï¸ æ§åˆ¶é¢æ¿")
        
        # APIçŠ¶æ€æ£€æŸ¥
        if show_api_status(client):
            st.success("ğŸŸ¢ æœåŠ¡åœ¨çº¿")
        else:
            st.error("ğŸ”´ æœåŠ¡ç¦»çº¿")
        
        st.markdown("---")
        
        # é¡µé¢å¯¼èˆª
        page = st.selectbox(
            "é€‰æ‹©åŠŸèƒ½é¡µé¢",
            ["ğŸ¯ æ¨èæœåŠ¡", "ğŸ“Š æ•°æ®åˆ†æ", "âš™ï¸ APIé…ç½®"],
            index=0
        )
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    if page == "ğŸ¯ æ¨èæœåŠ¡":
        show_recommendation_interface(client)
    elif page == "ğŸ“Š æ•°æ®åˆ†æ":
        show_analytics_dashboard()
    elif page == "âš™ï¸ APIé…ç½®":
        show_api_configuration()
    
    # é¡µè„š
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center'>
        <small>LightGCNæ¨èç³»ç»Ÿ | åŸºäºONNXçš„é«˜æ€§èƒ½æ¨ç†æœåŠ¡</small>
        </div>
        """, 
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()