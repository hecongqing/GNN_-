#!/usr/bin/env python3
"""
åŸºäºONNXçš„LightGCNæ¨èæœåŠ¡å™¨
æä¾›HTTP APIæ¥å£è¿›è¡Œæ¨ç†
"""

import os
import sys
import json
import numpy as np
from typing import List, Dict, Any, Optional
import argparse
import logging
from pathlib import Path

from flask import Flask, request, jsonify, abort
import onnxruntime as ort

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from src.utils import setup_logger


class ONNXRecommendationServer:
    """åŸºäºONNXçš„æ¨èæœåŠ¡å™¨"""
    
    def __init__(self, model_path: str, metadata_path: str = None):
        """
        åˆå§‹åŒ–ONNXæ¨èæœåŠ¡å™¨
        
        Args:
            model_path: ONNXæ¨¡å‹æ–‡ä»¶è·¯å¾„
            metadata_path: æ¨¡å‹å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.model_path = model_path
        self.metadata_path = metadata_path or model_path.replace('.onnx', '_metadata.json')
        self.logger = setup_logger('ONNXServer')
        
        # æ¨¡å‹ç›¸å…³
        self.session = None
        self.input_name = None
        self.output_names = None
        
        # å…ƒæ•°æ®
        self.n_users = 0
        self.n_items = 0
        self.embedding_dim = 64
        self.n_layers = 3
        
        # ç”¨æˆ·-ç‰©å“äº¤äº’æ•°æ®ï¼ˆç”¨äºæ¨ç†ï¼‰
        self.edge_index = None
        
        # åˆå§‹åŒ–
        self.load_model()
        self.load_metadata()
        self.prepare_inference_data()
        
    def load_model(self):
        """åŠ è½½ONNXæ¨¡å‹"""
        self.logger.info(f"åŠ è½½ONNXæ¨¡å‹: {self.model_path}")
        
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ONNXæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        
        try:
            # åˆ›å»ºONNX Runtimeä¼šè¯
            self.session = ort.InferenceSession(self.model_path)
            
            # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
            self.input_name = self.session.get_inputs()[0].name
            self.output_names = [output.name for output in self.session.get_outputs()]
            
            self.logger.info(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè¾“å…¥: {self.input_name}, è¾“å‡º: {self.output_names}")
            
        except Exception as e:
            self.logger.error(f"åŠ è½½ONNXæ¨¡å‹å¤±è´¥: {e}")
            raise
    
    def load_metadata(self):
        """åŠ è½½æ¨¡å‹å…ƒæ•°æ®"""
        if os.path.exists(self.metadata_path):
            self.logger.info(f"åŠ è½½å…ƒæ•°æ®: {self.metadata_path}")
            
            with open(self.metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            self.n_users = metadata.get('n_users', 1000)
            self.n_items = metadata.get('n_items', 500)
            self.embedding_dim = metadata.get('embedding_dim', 64)
            self.n_layers = metadata.get('n_layers', 3)
            
            self.logger.info(f"å…ƒæ•°æ®åŠ è½½å®Œæˆ - ç”¨æˆ·æ•°: {self.n_users}, ç‰©å“æ•°: {self.n_items}")
        else:
            self.logger.warning(f"å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.metadata_path}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    
    def prepare_inference_data(self):
        """å‡†å¤‡æ¨ç†æ•°æ®"""
        self.logger.info("å‡†å¤‡æ¨ç†æ•°æ®...")
        
        # åˆ›å»ºç¤ºä¾‹è¾¹ç´¢å¼•ï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥ä»æ•°æ®åº“æˆ–æ–‡ä»¶åŠ è½½ï¼‰
        # è¿™é‡Œåˆ›å»ºä¸€ä¸ªç¨€ç–çš„ç”¨æˆ·-ç‰©å“äº¤äº’çŸ©é˜µ
        num_edges = min(self.n_users * 5, 10000)
        
        user_indices = np.random.randint(0, self.n_users, num_edges)
        item_indices = np.random.randint(0, self.n_items, num_edges) + self.n_users
        
        self.edge_index = np.stack([user_indices, item_indices])
        
        self.logger.info(f"æ¨ç†æ•°æ®å‡†å¤‡å®Œæˆï¼Œè¾¹æ•°: {num_edges}")
    
    def get_user_recommendations(self, user_id: int, top_k: int = 10) -> List[int]:
        """
        ä¸ºæŒ‡å®šç”¨æˆ·ç”Ÿæˆæ¨è
        
        Args:
            user_id: ç”¨æˆ·ID
            top_k: æ¨èç‰©å“æ•°é‡
            
        Returns:
            æ¨èçš„ç‰©å“IDåˆ—è¡¨
        """
        if user_id < 0 or user_id >= self.n_users:
            raise ValueError(f"ç”¨æˆ·ID {user_id} è¶…å‡ºèŒƒå›´ [0, {self.n_users})")
        
        try:
            # è¿è¡ŒONNXæ¨ç†
            outputs = self.session.run(
                self.output_names,
                {self.input_name: self.edge_index}
            )
            
            user_embeddings, item_embeddings = outputs
            
            # è®¡ç®—ç”¨æˆ·ä¸æ‰€æœ‰ç‰©å“çš„ç›¸ä¼¼åº¦åˆ†æ•°
            user_emb = user_embeddings[user_id:user_id+1]  # [1, embedding_dim]
            scores = np.dot(user_emb, item_embeddings.T).squeeze()  # [n_items]
            
            # è·å–Top-Kæ¨è
            top_items = np.argsort(scores)[-top_k:][::-1]
            
            return top_items.tolist()
            
        except Exception as e:
            self.logger.error(f"æ¨ç†å¤±è´¥: {e}")
            raise
    
    def get_batch_recommendations(self, user_ids: List[int], top_k: int = 10) -> Dict[int, List[int]]:
        """
        æ‰¹é‡ç”Ÿæˆæ¨è
        
        Args:
            user_ids: ç”¨æˆ·IDåˆ—è¡¨
            top_k: æ¨èç‰©å“æ•°é‡
            
        Returns:
            ç”¨æˆ·IDåˆ°æ¨èåˆ—è¡¨çš„æ˜ å°„
        """
        recommendations = {}
        
        for user_id in user_ids:
            try:
                recommendations[user_id] = self.get_user_recommendations(user_id, top_k)
            except Exception as e:
                self.logger.error(f"ç”¨æˆ· {user_id} æ¨èå¤±è´¥: {e}")
                recommendations[user_id] = []
        
        return recommendations
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        return {
            'status': 'healthy',
            'model_path': self.model_path,
            'n_users': self.n_users,
            'n_items': self.n_items,
            'embedding_dim': self.embedding_dim,
            'n_layers': self.n_layers
        }


# Flaskåº”ç”¨
app = Flask(__name__)
server = None


@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    if server is None:
        abort(503)
    
    return jsonify(server.health_check())


@app.route('/recommend', methods=['POST'])
def recommend():
    """å•ç”¨æˆ·æ¨èæ¥å£"""
    if server is None:
        abort(503)
    
    try:
        data = request.get_json()
        user_id = data.get('user_id')
        top_k = data.get('top_k', 10)
        
        if user_id is None:
            return jsonify({'error': 'ç¼ºå°‘user_idå‚æ•°'}), 400
        
        recommendations = server.get_user_recommendations(user_id, top_k)
        
        return jsonify({
            'user_id': user_id,
            'recommendations': recommendations,
            'top_k': top_k
        })
        
    except ValueError as e:
        return jsonify({'error': str(e)}), 400
    except Exception as e:
        app.logger.error(f"æ¨èå¤±è´¥: {e}")
        return jsonify({'error': 'æ¨èæœåŠ¡å¼‚å¸¸'}), 500


@app.route('/recommend/batch', methods=['POST'])
def recommend_batch():
    """æ‰¹é‡æ¨èæ¥å£"""
    if server is None:
        abort(503)
    
    try:
        data = request.get_json()
        user_ids = data.get('user_ids', [])
        top_k = data.get('top_k', 10)
        
        if not user_ids:
            return jsonify({'error': 'ç¼ºå°‘user_idså‚æ•°'}), 400
        
        if len(user_ids) > 100:  # é™åˆ¶æ‰¹é‡å¤§å°
            return jsonify({'error': 'æ‰¹é‡è¯·æ±‚ä¸èƒ½è¶…è¿‡100ä¸ªç”¨æˆ·'}), 400
        
        recommendations = server.get_batch_recommendations(user_ids, top_k)
        
        return jsonify({
            'recommendations': recommendations,
            'top_k': top_k
        })
        
    except Exception as e:
        app.logger.error(f"æ‰¹é‡æ¨èå¤±è´¥: {e}")
        return jsonify({'error': 'æ‰¹é‡æ¨èæœåŠ¡å¼‚å¸¸'}), 500


@app.route('/info', methods=['GET'])
def info():
    """æ¨¡å‹ä¿¡æ¯æ¥å£"""
    if server is None:
        abort(503)
    
    return jsonify({
        'model_type': 'LightGCN',
        'format': 'ONNX',
        'n_users': server.n_users,
        'n_items': server.n_items,
        'embedding_dim': server.embedding_dim,
        'n_layers': server.n_layers
    })


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¯åŠ¨ONNXæ¨èæœåŠ¡å™¨')
    parser.add_argument('--model-path', type=str, required=True,
                       help='ONNXæ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--metadata-path', type=str,
                       help='æ¨¡å‹å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--host', type=str, default='0.0.0.0',
                       help='æœåŠ¡å™¨ä¸»æœºåœ°å€')
    parser.add_argument('--port', type=int, default=8080,
                       help='æœåŠ¡å™¨ç«¯å£')
    parser.add_argument('--debug', action='store_true',
                       help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–æœåŠ¡å™¨
        global server
        server = ONNXRecommendationServer(args.model_path, args.metadata_path)
        
        # é…ç½®æ—¥å¿—
        if not args.debug:
            logging.getLogger('werkzeug').setLevel(logging.WARNING)
        
        print(f"ğŸš€ ONNXæ¨èæœåŠ¡å™¨å¯åŠ¨æˆåŠŸï¼")
        print(f"ğŸ“ åœ°å€: http://{args.host}:{args.port}")
        print(f"ğŸ“‹ å¥åº·æ£€æŸ¥: http://{args.host}:{args.port}/health")
        print(f"ğŸ” æ¨¡å‹ä¿¡æ¯: http://{args.host}:{args.port}/info")
        
        # å¯åŠ¨Flaskåº”ç”¨
        app.run(
            host=args.host,
            port=args.port,
            debug=args.debug,
            threaded=True
        )
        
    except Exception as e:
        print(f"âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())